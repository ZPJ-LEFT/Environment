# First steps with CARLA

Carla是一个生成自动驾驶和其他机器人应用模拟数据的综合解决方案。

在本指南中，我们将学习carla的标准工作流程，从启动服务器、连接客户端，到添加载具、感知器并且生成数据，并且秉持一切从简的原则，以最高效的方式展示数据的生成流程。

## 启动Carla并且连接客户端

Carla可以通过在命令行内打开可执行文件启动。

为了通过Python API控制CARLA，我们需要通过公开端口使Python客户端连接到服务器端，用户就是通过client对象和world对象控制模拟的。新建一个Python脚本，输入以下内容：

```python
import carla
import random

# Connect to the cilent and retrieve the world object
client = carla.Client('localhost',2000)
world = client.get_world()
```

Client对象用于维护客户端和服务器的连接，并且具有施加指令、加载数据、导出数据的功能。

## 加载地图

在CARLA的API中，world对象提供对模拟内所有元素的访问接口，包括地图以及地图内的对象，如建筑物、交通信号灯、车辆、行人。CARLAR服务器默认加载地图Town10，如果希望更换地图，运行 `config.py` 脚本：

```
./config.py --map Town06
```

我们也可以利用world对象从client中加载地图：

```
client.load_world('Town05')
```

## 视觉导航

Spector是模拟的一个视角，你可以使用 `WASDQE` 和鼠标拖拽控制它。

Spector及其属性可以通过Python API控制：

```python
# Retrieve the spectator object
spectator = world.get_spectator()

# Get the location and rotation of the spectator through its transform
transform = spectator.get_transform()

location = transform.location
rotation = transform.rotation

# Set the spectator with an empty transform
spectator.set_transform(carla.Transform())
# This will set the spectator at the origin of the map, with 0 degrees
# pitch, yaw and roll - a good way to orient yourself in the map
```

## 添加NPCs

为了生成载具，你需要先从蓝图库中选择载具：

```python
# Get the blueprint library and filter for the vehicle blueprints
vehicle_blueprints = world.get_blueprint_library().filter('*vehicle*')
```

下一步选择出生点，并生成载具：

```python
# Get the map's spawn points
spawn_points = world.get_map().get_spawn_points()

# Spawn 50 vehicles randomly distributed throughout the map 
# for each spawn point, we choose a random vehicle from the blueprint library
for i in range(0,50):
    world.try_spawn_actor(random.choice(vehicle_blueprints), random.choice(spawn_points))
```

下一步生成模拟的中心载具，它将是自动驾驶所控制的载具，在carla中，我们称它为"Ego vehicle":

```python
ego_vehicle = world.spawn_actor(random.choice(vehicle_blueprints), random.choice(spawn_points))
```

除了车辆，carla还提供了行人的模拟，车辆和行人被统称为 **actor**，在此先省略不谈。

## 添加感知器

我们将一个普通相机添加到ego vehicle以记录视频数据：

```python
# Create a transform to place the camera on top of the vehicle
camera_init_trans = carla.Transform(carla.Location(z=1.5))

# We create the camera through a blueprint that defines its properties
camera_bp = world.get_blueprint_library().find('sensor.camera.rgb')

# We spawn the camera and attach it to our ego vehicle
camera = world.spawn_actor(camera_bp, camera_init_trans, attach_to=ego_vehicle)
```

一旦相机被生成，我们需要调用`listen()`记录数据，`listen()`将一个callback作为参数，该callback定义了如何处理数据，你可以将数据流传入另一个程序或保存到磁盘。

本示例使用lambda函数作为回调函数，以保存数据到磁盘：
```python
# Start camera with PyGame callback
camera.listen(lambda image: image.save_to_disk('out/%06d.png' % image.frame))
```

有许多可用的感知器可以选择，在此略过不表。

### 使用Traffic manager制作载具动画

Traffic manager是carla的一个控制车辆自动行驶的组件。

通过以下指令，将车辆的控制权移交给Traffic manager：

```python
for vehicle in world.get_actors().filter('*vehicle*'):
    vehicle.set_autopilot(True)
```

### 将一个载具定义为Ego Vehicle

再次强调，Ego Vehicle是模拟资源加载的中心，使用以下指令定义它：

```python
ego_bp = world.get_blueprint_library().find('vehicle.lincoln.mkz_2020')
ego_bp.set_attribute('role_name', 'hero')
ego_vehicle = world.spawn_actor(ego_bp, random.choice(spawn_points))
```

### 选择地图

你可以通过该指令浏览所有可用的地图：

```
client.get_available_maps()
```

当你选中一张地图，使用该指令加载它：

```
client.load_world('Town03_Opt')
```

### 选择载具

你可以通过该指令浏览所有可用的载具蓝图：

```python
for bp in world.get_blueprint_library().filter('vehicle'):
    print(bp.id)
```
