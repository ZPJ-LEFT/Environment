# SAMFlow: Eliminating Any Fragmentation in Optical Flow with Segment Anything Model

## 摘要
光流估计的目的是寻找两帧之间的2D密集运动场，由于模型结构和训练数据集的限制，已有方法通常过多依赖于本地线索，忽略了物体的完整性，这导致了碎片化的运动估计

通过理论分析，论文发现预训练的视觉大模型有助于光流估计，并且论文注意到近期SAM对整个物体的分割表现出很强的能力，它十分适合于解决碎片化估计的问题

论文因此提出一个解决方案：将已训练好的SAM图像编码器冻结并嵌入到FlowFormer中来增强物体感知

为了使SAM适应于非分割任务如光流估计，论文提出一个光流任务特定的改编方案，包括将SAM编码器与光流上下文编码器融合的上下文融合模块、用任务特定的可学习嵌入改编SAM特征的上下文改编模块

论文提出的SAMFlow在Sintel和KITTI-15上实现了0.86/2.10(clean/final, EPE)和3.55/12.32(EPE/F1-all)，比FlowFormer高出8.5%/9.9%和13.2%/16.3%

此外，论文模型在Sintel和KITTI-15上实现了SOTA性能，在Sintel clean的两帧方法中上实现了第一

## 引言

尽管光流估计的算法性能已经获得了飞跃，但已有的光流算法仍被两个因素限制：
（1）缺乏具有良好标签的数据集
（2）缺乏高层次的感知理解能力

近期的视觉大模型十分适合解决上述问题：
（1）FlowFormer++, MatchFlow表明利用非光流数据进行预训练监督有利于最终的光流估计，这证明预训练的视觉大模型能利用更广泛的无标签图像，缓解光流数据集的稀疏性
（2）预训练的视觉表征中包含论文需要的高层次理解
因此，论文提出利用SAM的编码特征作为光流估计的特征提取结果

然后，直接将SAM特征利用到非分割任务如光流中是十分困难的，因为它们缺少了很多任务特定的知识，论文提出了一种针对光流任务的改编方案，设计了Context Fusion Module (CFM)和Context Adaption Module (CAM)，基于以上改进，论文提出的SAMFlow实现了很好的结果

总之，贡献如下：
（1）首次发现预训练的SAM可以用于光流估计，并提出了SAMFlow
（2）为了防止任务间的不匹配影响精度，提出了针对光流任务的改编方案，引入CFM和CAM
（3）SAM实现了SOTA性能

## 精髓点

（1）立意层面：解决光流的Fragementation问题
（2）理论层面：结合概率论，对光流任务的cost query和context进行理论推导与分析
（3）模型层面：将预训练大模型的Encoder与SOTA模型的Architecture结合，加上有效的融合模块
（4）性能层面：SOTA性能，且以巧妙的形式展示了运行速度

## 启发

利用已有的架构，尤其是那些被充分训练的模型，结合任务背景搭建新的模型，关键在于要解决一个问题
